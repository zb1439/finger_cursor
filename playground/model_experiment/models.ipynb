{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4da5655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (1.10.2)\n",
      "Requirement already satisfied: torchvision in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (0.11.3)\n",
      "Requirement already satisfied: torchaudio in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (0.10.2)\n",
      "Requirement already satisfied: typing-extensions in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: ipywidgets in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: entrypoints in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: argon2-cffi in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: nbconvert in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: testpath in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.11)\n",
      "Requirement already satisfied: packaging in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: webencodings in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n",
      "Requirement already satisfied: sklearn in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/siqijiang/anaconda3/envs/fingercursor/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio # Default to CUDA 10.2 https://pytorch.org/get-started/locally/\n",
    "!pip install ipywidgets\n",
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80a8f9-3599-4a9f-a284-2ce76f61257f",
   "metadata": {},
   "source": [
    "## Read Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f987f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "label_names = ['finger_point', 'fist', 'index_pick', 'middle_pick', 'palm', 'thumb_up', 'victory']\n",
    "# matching_label = [\"n/a\", \"drag\", \"point\", \"swipe\", \"click\", \"right-click\"]\n",
    "# mapping_dict = {\n",
    "#     0: 0,\n",
    "#     1: 1,\n",
    "#     2: 4,\n",
    "#     3: 5,\n",
    "#     4: 2,\n",
    "#     5: 0,\n",
    "#     6: 0\n",
    "# }\n",
    "\n",
    "def readData(directory):\n",
    "    data = []\n",
    "    img_data = []\n",
    "    y = []\n",
    "    y_i = []\n",
    "    cropped_img_data = []\n",
    "    # Data being read here\n",
    "    # Default directory name ./data_collector/(gesture type)/(image/label)\n",
    "    \n",
    "    for i, folder in enumerate(label_name):\n",
    "        baseD = os.path.join(directory, folder)\n",
    "        labelsD = os.path.join(baseD, 'labels')\n",
    "        imageD = os.path.join(baseD, 'images')\n",
    "\n",
    "        for filename in os.listdir(labelsD):\n",
    "            labelFileName = os.path.join(labelsD, filename)\n",
    "            imageFileName = os.path.join(imageD, filename.split('.')[0] + \".png\")\n",
    "\n",
    "            with open(labelFileName, 'r') as f:\n",
    "                data.append(json.load(f))\n",
    "                y.append(folder)\n",
    "                y_i.append(i)\n",
    "                f.close()\n",
    "\n",
    "            img_data.append(Image.open(imageFileName))\n",
    "            \n",
    "            im = img_data[-1].copy()\n",
    "            landmark = data[-1]['multi_hand_landmarks']\n",
    "            xs = [int(l['x'] * im.size[0]) for l in landmark]\n",
    "            ys = [int(l['y'] * im.size[1]) for l in landmark]\n",
    "            boundary_x_left = max(0, min(xs) - 50)\n",
    "            boundary_x_right = min(im.size[0], max(xs) + 50)\n",
    "            boundary_y_up = max(0, min(ys) - 50)\n",
    "            boundary_y_down = min(im.size[1], max(ys) + 50)\n",
    "            \n",
    "            im = im.crop((boundary_x_left, boundary_y_up, boundary_x_right, boundary_y_down))\n",
    "            cropped_img_data.append(im)\n",
    "\n",
    "    return np.array(data), np.array(img_data), np.array(y), np.array(y_i), np.array(cropped_img_data)\n",
    "\n",
    "\n",
    "def balance_data(data, img_data, y_i, cropped_img):\n",
    "    # Balance data classes. \n",
    "    y_counts = np.bincount(y_i)\n",
    "    num_per_y = y_counts.min()\n",
    "    final_sel = np.ones(len(y_i), dtype = 'bool')\n",
    "    for i in range(len(label_names)):\n",
    "        sel = np.array(y_i) == i\n",
    "        sel[np.where(sel)[0][:num_per_y]] = False\n",
    "        final_sel[sel] = False\n",
    "\n",
    "    data_X = data[final_sel]\n",
    "    data_y = y_i[final_sel]\n",
    "    img_data_X = img_data[final_sel]\n",
    "    cropped = cropped_img[final_sel]\n",
    "    \n",
    "    return data_X, img_data_X, data_y, cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da0fad-21c4-4bb7-be82-4138ca697b77",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1078d5-53d2-48ed-8084-af86b714b733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1250077/1833855824.py:47: FutureWarning: The input object of type 'PngImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'PngImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data), np.array(img_data), np.array(y), np.array(y_i), np.array(cropped_img_data)\n",
      "/tmp/ipykernel_1250077/1833855824.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), np.array(img_data), np.array(y), np.array(y_i), np.array(cropped_img_data)\n",
      "/tmp/ipykernel_1250077/1833855824.py:47: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data), np.array(img_data), np.array(y), np.array(y_i), np.array(cropped_img_data)\n"
     ]
    }
   ],
   "source": [
    "DIR1 = './data_collector'\n",
    "DIR2 = './test_data'\n",
    "DIR3 = './skye'\n",
    "DIR4 = './kenny'\n",
    "\n",
    "data1, img_data1, y1, y1_i, cropped_img_data1 = readData(DIR1)\n",
    "data1_balanced, img_data1_balanced, y1_i_balanced, cropped_img_data1_balanced = \\\n",
    "    balance_data(data1, img_data1, y1_i, cropped_img_data1)\n",
    "\n",
    "data2, img_data2, y2, y2_i, cropped_img_data2 = readData(DIR2)\n",
    "data2_balanced, img_data2_balanced, y2_i_balanced, cropped_img_data2_balanced = \\\n",
    "    balance_data(data2, img_data2, y2_i, cropped_img_data2)\n",
    "\n",
    "data3, img_data3, y3, y3_i, cropped_img_data3 = readData(DIR3)\n",
    "data3_balanced, img_data3_balanced, y3_i_balanced, cropped_img_data3_balanced = \\\n",
    "    balance_data(data3, img_data3, y3_i, cropped_img_data3)\n",
    "\n",
    "data4, img_data4, y4, y4_i, cropped_img_data4 = readData(DIR4)\n",
    "data4_balanced, img_data4_balanced, y4_i_balanced, cropped_img_data4_balanced = \\\n",
    "    balance_data(data4, img_data4, y4_i, cropped_img_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f69409-af5d-41ed-bda0-7e27c35d849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = np.concatenate((data1, data2, data4), axis = 0)\n",
    "train1_img = np.concatenate((img_data1, img_data2, img_data4), axis = 0)\n",
    "train_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0623f04f-e3d7-428e-905e-4be286b54f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4192\n"
     ]
    }
   ],
   "source": [
    "total_data = np.concatenate((data1, data2, data4), axis = 0)\n",
    "total_img_data = np.concatenate((img_data1, img_data2, img_data4), axis = 0)\n",
    "# total_y = np.concatenate((y1, y2, y4), axis = 0)\n",
    "total_y_i = np.concatenate((y1_i, y2_i, y4_i), axis = 0)\n",
    "total_cropped = np.concatenate((cropped_img_data1, cropped_img_data2, cropped_img_data4), axis = 0)\n",
    "\n",
    "total_data_balanced, total_img_data_balanced, total_y_i_balanced, total_cropped_balanced = \\\n",
    "    balance_data(total_data, total_img_data, total_y_i, total_cropped)\n",
    "\n",
    "print(len(total_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d988d-51a2-4b51-8298-738e8d7db3c5",
   "metadata": {},
   "source": [
    "## Use MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9f756f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mlp_data(data, y):\n",
    "    aa = []\n",
    "    X = []\n",
    "    for a in data : aa.append(a['multi_hand_landmarks'])\n",
    "    for d in aa:\n",
    "        singleData = []\n",
    "        for landmark in d:\n",
    "            singleData.append(landmark['x'])\n",
    "            singleData.append(landmark['y'])\n",
    "            singleData.append(landmark['z'])\n",
    "        X.append(singleData)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# X, y = extract_mlp_data(data1_balanced, y1_i_balanced)\n",
    "X, y = extract_mlp_data(total_data_balanced, total_y_i_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5090af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, )\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100), max_iter=100000, learning_rate='adaptive').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34fe0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9895324494068388\n",
      "0.9860724233983287\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "902fbe66-82ed-4d11-8f54-e574ab70be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8161953727506427\n"
     ]
    }
   ],
   "source": [
    "t_X, t_y = extract_mlp_data(data3, y3_i)\n",
    "print(clf.score(t_X, t_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db047b28-212f-45f7-bfe6-05db16b29acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"mlp_classifier.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "14ef8881-5067-4950-ab88-0db3cfcec2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0] * 3 * 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2bee1c6e-36be-4496-824b-576fe79cd25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "1 0.7615894039735099\n",
      "2 0.9672131147540983\n",
      "3 0.0\n",
      "4 1.0\n",
      "5 1.0\n",
      "6 1.0\n"
     ]
    }
   ],
   "source": [
    "# gesture not accurate: 1, 3\n",
    "\n",
    "for i in range(0, 7):\n",
    "    print(i, clf.score(t_X[t_y == i], t_y[t_y == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d56853",
   "metadata": {},
   "source": [
    "## Use MobileNet v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e354e704-0a7a-4926-af5d-05029ee588f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1792, 3, 256, 256])\n",
      "(1792,)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def preprocess_mobilenet_data(imdata):\n",
    "    # Resize data. \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    processed = [preprocess(im) for im in imdata]\n",
    "    processed = torch.stack(processed)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "preprocessed_img_data = preprocess_mobilenet_data(total_cropped_balanced)\n",
    "data_X = preprocessed_img_data\n",
    "data_y = total_y_i_balanced\n",
    "print(data_X.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4b56cb8-708e-426e-82bf-e1f8f8c4d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im in preprocessed_img_data[:5]:\n",
    "#     plt.imshow(np.transpose(im, (1, 2, 0)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7927eb8a-2d46-477d-a3ce-3854cb35fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179 179 179 180 179 179 179]\n",
      "[77 77 77 76 77 77 77]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, stratify=data_y, test_size=0.3)\n",
    "\n",
    "def get_dataloader(X, y):\n",
    "    dataloader = DataLoader(\n",
    "        [(X[i], y[i]) for i in range(len(X))], \n",
    "        batch_size=16, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(X_train, y_train)\n",
    "print(np.bincount(y_train))\n",
    "\n",
    "test_dataloader = get_dataloader(X_test, y_test)\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2dacc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "def get_model(freeze_extraction_layers = False):\n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "    model.classifier[1] = nn.Linear(model.last_channel, len(label_names))\n",
    "\n",
    "    if (freeze_extraction_layers):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for layer in model.classifier:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "    if torch.cuda.is_available():\n",
    "        model.to('cuda')\n",
    "    return model\n",
    "\n",
    "model = get_model(freeze_extraction_layers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d3e36ad4-5277-48aa-a616-716d60f9d33e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcc659-c771-44a9-be6c-c1b108d62394",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ffc75f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    79] loss: 0.026\n",
      "accuracy: 0.9880382775119617\n",
      "[2,    79] loss: 0.033\n",
      "accuracy: 0.9880382775119617\n",
      "[3,    79] loss: 0.034\n",
      "accuracy: 0.9904306220095693\n",
      "[4,    79] loss: 0.018\n",
      "accuracy: 0.992822966507177\n",
      "[5,    79] loss: 0.019\n",
      "accuracy: 0.9936204146730463\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, dataloader, lr = 1e-4, num_epoch = 30):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    PRINT_BATCH_NUM = len(dataloader)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 1e100000\n",
    "\n",
    "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).float().sum().item()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            if i % PRINT_BATCH_NUM == (PRINT_BATCH_NUM - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / PRINT_BATCH_NUM:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        epoch_acc = correct / len(dataloader.dataset)\n",
    "        epoch_loss = epoch_loss / len(dataloader.dataset)\n",
    "        print(f'accuracy: {epoch_acc}')\n",
    "\n",
    "        if (epoch_loss < best_loss):\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), f'model_parameters_loss_{best_loss:.6f}.pt')\n",
    "\n",
    "    return best_acc, best_loss\n",
    "best_acc, best_loss = train(model, train_dataloader, lr = 1e-4, num_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5db926f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model_parameters_loss_0.000010.pt\n",
      "0.08411999408781412\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def load_model_state(model, best_loss):\n",
    "    best_model_name = f'model_parameters_loss_{best_loss:.6f}.pt'\n",
    "    print(f'loading {best_model_name}')\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_name))\n",
    "\n",
    "def eval_model(model, dataloader, print_graph = False):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    y_pred = None\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.max(outputs.data, 1)[1]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            correct += (pred == labels).float().sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (y_pred is None):\n",
    "                y_pred = pred.unsqueeze(-1).cpu().detach()\n",
    "            else:\n",
    "                y_pred = torch.vstack((y_pred, pred.unsqueeze(-1).cpu().detach()))\n",
    "\n",
    "            if print_graph:\n",
    "                for j in range(len(inputs)):\n",
    "                    plt.imshow(inputs[j].cpu().permute(1, 2, 0))\n",
    "                    plt.show()\n",
    "                    print(f\"Label: {labels[j]}, {label_names[labels[j]]}\")\n",
    "                    print(f\"Pred: {pred[j]}, {label_names[pred[j]]}\")\n",
    "\n",
    "        acc = correct / len(dataloader.dataset)\n",
    "\n",
    "    print(running_loss)\n",
    "    print(acc)\n",
    "# for i in np.unique(y_test):\n",
    "#     print(i)\n",
    "#     print((y_pred[y_test == i, 0] == i).sum() / np.bincount(y_test)[i])\n",
    "load_model_state(model, best_loss)\n",
    "eval_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4b08b25-8e67-4854-9ec9-d0558980a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_y_i = np.array(y3_i)\n",
    "t_preprocessed_img_data = preprocess_mobilenet_data(cropped_img_data3)\n",
    "t_dataloader = get_dataloader(t_preprocessed_img_data, t_y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ef74379e-f996-426d-b421-2545ca5bfe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.93533551692963\n",
      "0.6066838046272494\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, t_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23e844a6-bba6-4f6d-9447-7fbb2ae28812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"mobilenet.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea162cf1-d1a2-4393-baaa-e82008a554bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 7):\n",
    "    print(i, clf.score(t_X[t_y == i], t_y[t_y == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ee1bb-a971-4645-96b2-bf611da7acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 epoch: ~0.5\n",
    "# 10 epoch: 0.622107969151671\n",
    "# 15 epoch: 0.6066838046272494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8971d277-00aa-4038-b7e7-a4f03101756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24519368447363377\n",
      "1.0\n",
      "0 None\n",
      "4.293209105730057\n",
      "0.7682119205298014\n",
      "1 None\n",
      "17.055834412574768\n",
      "0.5081967213114754\n",
      "2 None\n",
      "80.80855464935303\n",
      "0.0\n",
      "3 None\n",
      "0.0394152132794261\n",
      "1.0\n",
      "4 None\n",
      "0.016224675986450166\n",
      "1.0\n",
      "5 None\n",
      "6.033066987991333\n",
      "0.7565217391304347\n",
      "6 None\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 7):\n",
    "    t_mp = get_dataloader(preprocess_mobilenet_data(cropped_img_data3[y3_i == i]), \n",
    "                          np.array(y3_i[y3_i == i]))\n",
    "    print(i, eval_model(model, t_mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83607c60-a631-44dd-abbf-19a708b60374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
